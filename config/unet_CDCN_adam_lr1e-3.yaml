output_dir: '../output/'
log_dir: '../output/log'
device: 'gpu'
dataset:
  train_mode: 'CelebA_Spoof_train' # 'train', 'CelebA_Spoof'
  test_mode: 'CelebA_Spoof_test'   # 'test', 'CelebA_Spoof'
  name: 'rose'
  root: '/data/04ab8be3dd3742a7bac01b89faab5316/'
#   root: '/data/4ffb7bc8fd8d4055bca70b7dc401efbb/label_normal/'
#  root: '/data/4ffb7bc8fd8d4055bca70b7dc401efbb/'
#   root: '/data/0b5e468efcfd4dd4b61461527c6f9d94/'
#   root: '/data/e6a31fbc6b594c0795e6add0230d4bab/'
#   root: '/data/4bc65ee9875d4554bea45da9c90aa461/'
  augmentation:
    horizontal_flip: True
    vertial_flip: False
    rotation: 10
  train_set: 
      train_set: '0818_gloabal_train_new_data_add_low_phone_bmp_new.txt'                                 #  acc:0.99714, tpr:0.99477, fpr:0.00100
      train_set1: 'train_label.txt'                                                                      #  acc:
  test_set: 
    test_set1: '220200612_all_phone_data_test_crop/test_list_220200612_all_phone_data_test_crop.txt' # 200765 acc:0.79486/74665, tpr:0.73213/58500, fpr:0.12374/04360
    test_set2: 'data_crop_test_sdb3/test_sdb3.txt'                                                   # 65366  acc:0.86310/93079, tpr:0.79592/90159, fpr:0.06211/03675
    test_set3: 'data_crop_test_sdb5/test_list_data_crop_test_sdb5.txt'                               # 231541 acc:0.69363/70326, tpr:0.70952/63937, fpr:0.32551/21980
    test_set4: 'test_result_bmp_new/test_all.txt'                                                    # 121823 acc:0.82977/89937, tpr:0.97223/97844, fpr:0.72030/40596
    test_CelebA_Spoofing: 'test_label.txt'                                                           # 67170  acc:0.25857, tpr:0.18431,  fpr:0.56543
  mean: [0.5,0.5,0.5]
  sigma: [0.5,0.5,0.5]
model:
  base: 'LGSC'
  encoder_arch: 'one_stream_arch' # types = (one_stream_arch, two_stream_arch)
  backbone: 'lcnet_small' # types = (lcnet_small, liveness_small, MobileNetV2_small)
  header_type: 'patch_pixel' # types = (pixel, binary, combined, patch_pixel, binary_classification)
  pretrained: False
  num_output: 2
  image_size: [224,224] # types = ([224,224], [128,128])  
  patch_size: 16 # types = (8, 16, 28)  
  map_size: 112  # types = (28, 14, 8)  
  smoothing: True
  dropout_prob: 0.2
train:
  batch_size: 256 # types = (1024, 512, 300, 256, 200, 8)  
  optimizer: 'AdamW' # types = (adam, AdamW)
  lr: 0.0001
  warm_up_ratio: 0.1 # types = (0, 0.01, 0.1)
  num_epochs: 50 # types = (20, 50, 100)
  loss:
    w_cls: 0.0
    w_reg: 1.0
    w_tri: 0.0
#   loss:
#     w_cls: 5.0
#     w_reg: 3.0
#     w_tri: 1.0
test:
  batch_size: 256 # types = (512, 256, 128, 8)  