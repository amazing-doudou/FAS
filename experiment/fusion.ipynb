{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_size 14\n",
      "map_size 16\n",
      "scale 16\n",
      "L 256\n"
     ]
    }
   ],
   "source": [
    "mask_index = torch.tensor([ 461,  837,  939,  566,  645,  193,  769,   61,  882,  215,   19,  784,\n",
    "         120,  447,  555,  219,  460,  588,  192,  591,  807,  168,  732,   95,\n",
    "         206,  640,  472,  965,  923,  754,  562,  391,  169,  711,  757,  275,\n",
    "         990,   56,  822, 1006,  304,  834,  421,  967,  406,   21,  865,  809,\n",
    "         218,  880,  232,  813,  375,  791,  979,  301,  870,  365,  226,  429,\n",
    "         802,  496,  781,  437,  702,  343,  993,  505,  770,  435,  418,  682,\n",
    "         497,  765,  228,  886, 1008,  805, 1014,  905,  646,  426,  286,  912,\n",
    "           9,  677,  272,  956,  323,   51,  338,  112,    3,  544,  389,  415,\n",
    "          83,  367,  700,  609,  308,  571,  273,  445,  654,  973,  184,   47,\n",
    "         310,  596,  104,  140,  370,  638,  351,  740,  205,  691,  560,  884,\n",
    "         366,  161,  289,  213,  315,  981,  346,  594,  756,  689,  663,  281,\n",
    "         975,  709,  357,  561,  312,  514,  727,  926,  412,  534,  610,  930,\n",
    "         533,  935,  480,  225,  719,  252,  751,  994,  852,  898,   65,  674,\n",
    "         278,  823,  578,  150,  175,  414,  908,  280,  494,  204,  299,  872,\n",
    "         551,  262,  992,  657, 1019,  331,  518,  866,  649,  174,  873,  532,\n",
    "         706,  778,  574,  940,    8,  485,  543,  261,  844,  488,   68,   63,\n",
    "         737,   46,  348,  787,  927,   99,  564,  938,  115,  189,  878,  843,\n",
    "         969,  931,  245,   44,  293,  699,  735,   13,    5,  941,  879,  936,\n",
    "          87,  966,  814,    0,  350,  455,  786,  730,  601,  306,  983,  424,\n",
    "         972,  202,  783,  129,  808,  766,  106,  964,  236,  522,  179,  303,\n",
    "         309,  268,  393,  669,  900,  408, 1005,  271,  742,  883,  623,  392,\n",
    "        1018,  853,   94,  842,  282,  914,  153,  637,  139,  438,  921,  459,\n",
    "         124,  487,  298,  208,  903,  190,  433,  517,  630,  829,   79,  658,\n",
    "         196,  294,  811,   67,  656,   43,  877,  199,   22,  547,  287,  240,\n",
    "         714,  720,  224,  641,  373,  673,  386,  803,   30,   39,  133,  825,\n",
    "         894,  959,  249,  985,  123,  861,  648,  404,  971,  509,  499,  541,\n",
    "          86,  676,  531,  405,  670,  403,  513,  859,  483,  525, 1017,  501,\n",
    "         633,  622,  954,  748,  644,  989,  369,  957,  728,  846,  118,  446,\n",
    "         603,  871,   64,  432,  322,  667,  481,  200,  734,  416,  223,  970,\n",
    "          20,  953,  583,  259,  242,  538, 1013,  269,  722,  495,  207,  103,\n",
    "         158,  151,  758,  920,  355,  475,   97,  998,  554,  468,  753,  333,\n",
    "         830,  704,  948,  565,  855,  241,  907,  117,  379,  731,   50,  636,\n",
    "         606, 1010,  368, 1011,  498,  857,  995,  397,  162,  868,  826,  340,\n",
    "         626,  590,  138,  354,  651,  410,  387,  300,   32,  715,  436,   29,\n",
    "         160,    2,  817,  489,  466,  794,  345,  749,  359,  284,   28,  628,\n",
    "         321,  795,   71,  625,  307,  848,   38,  336,  172,  693,   53,  928,\n",
    "         605,  254,  869,  662,  600,  194,  686,  838,  741,  394,  696,   69,\n",
    "         119,  411,  524,  434,  568,  523,  186,  324,  317,  627,  469,  135,\n",
    "         395,  955,  585,  624, 1007,  863,  718,  381,  503,  776,  539,   40,\n",
    "         342,  329,  621,  458,   82,  789,  729,  130,  520,  171,  556,  587,\n",
    "         479,   45,  806,  276,  211,  474,  840,  771,  618,   52,  527,  762,\n",
    "         454,  502,  302,  542,  413,  110,  221,  701,  856,  747,  425,  712,\n",
    "         761, 1004,  888,  570,  647,  897,   80,  891,   16,  511,  141,  244,\n",
    "         320,  796,    4,  142,  950,  122,  430,   84,  105,  453, 1012, 1022,\n",
    "         145,  743,  383,  470,  264,   92,  109,  615,  799,  440,  270,  655,\n",
    "         867,  947,  692,  944,  529,  661,  220,  827,  924,  144,   88,  984,\n",
    "         170,  137,  451,  314,  183,  362,  185,  504,  328,  978,  372,  933,\n",
    "         326,  341,  723,  478,  632,  311, 1009,  707,  858,  635,  111,  353,\n",
    "         581,  607,  388,   10,   27,   60,  537, 1015,  710,  960,  203,  573,\n",
    "         549,  885,  951,  671,  982,  396,  774,  364,  344,  191,  650,  724,\n",
    "         422,  864,  248,  752,  100,  892,  725,  999,  816,  893,  572,  253,\n",
    "         611,  439,  976,  797,  942,  490,  231,   76,  132,  402,  356,  598,\n",
    "         876,  378,  932,  567,  339,  634,  945,  165,  319,  417,  777,  847,\n",
    "         216, 1002,  473,  708,  968,  918,  263,  937,  385, 1021,  147,  660,\n",
    "         849, 1000,  500,  452,  997,   90,  148,  267,  593,  552,  349,  180,\n",
    "         374,  559,  616,  604,  116,  579,  154,  325,   35,  283,   12,  815,\n",
    "         694,  963,  173,  530,  493,  237,  441,  819,  352,  916, 1003,    1,\n",
    "         305,   37,  358,  126,  772,  238,   15,  256,  785,  703,  265,  612,\n",
    "         296,  617,  376,  887,  217,  996,  230,  653,  643,  899,  602,   24,\n",
    "         292,  744,  229,  818,  197,   48,  295,  371,   78,  288,  327,   72,\n",
    "         235,  919, 1001,  695,  360,  759,  182,  526,  726,  443,  678,  507,\n",
    "         980,  462,  895,  779,  143,   25,  576,  906,  155,  291,  812,  159,\n",
    "           7,  279,  463,   23,  465,  101,  134,  114,  516,  212,  697,  380,\n",
    "         721,  839,  580,  127,  788,   58, 1023,   85,  290,  755,   77,   81,\n",
    "         401,  201,   34,  946,  431,  800,  181,  780,  136,  246,  457,  157,\n",
    "         297,  767,   89,  716,  736,  652,  875,  535,  113,  450,  492,    6,\n",
    "         738,  910,  198,  419,  904,  548,  862,  763,  746,  713,  557,   57,\n",
    "         471,  764,  698,  330,  683,  420,  773,   31,  874,  991,  188,  107,\n",
    "         582,  821,  482,  952,  508,  917,   14,  679,   33,  334,  987,  675,\n",
    "         613,  911,  901,  377,  750,  599,  589,   93,  407,  949,  266,  915,\n",
    "         149,  890,  828,  131,  247,  178,  782,  768,   59,  121,  597,  688,\n",
    "         836,   98,  477,  977,  913,  335,  550,  988,  845,  177,  166,  614,\n",
    "         672,  854,   73,  986,  313,  195,  486,   96,  316,  382,   26,  584,\n",
    "         801,  659,  102,  156,  347,  209,   18,  664,  824,  665,  810,  860,\n",
    "         575,  233,  187,  902,  125, 1020,  841,  934,   17,  277,  958,  428,\n",
    "         851,  274,  595,  668,   74,   75,  569,  176,  167,  608,  681,  519,\n",
    "         684,  922,  690,  545,  449,  510,  476,  798,  666,  222,   54,  639,\n",
    "         384,  337,  804,  962,  515,  258,  961,  733,   36,  558,  361,  553,\n",
    "         467,  442,  423,  243,  257,  790,  792,  251,  363,  881,  833,  563,\n",
    "         687,  835,  705,  925,  974,  128,  239,  400,  620,  250,   62,   55,\n",
    "         745,  831,  619,  850,  685,  943,  152,  820,  546,  398,  536,  427,\n",
    "          70,  506,  631,  227,  448,  108,  680,   11,  586,  889,  444,  793,\n",
    "         739,  390,  456,   41,  528,  285,  629,  214,  832,  484,  255,  146,\n",
    "         491, 1016,  909,   91,   42,  896,  399,  260,  409,  577,  642,  540,\n",
    "         521,  464,  234,  775,  512,  760,  929,  318,  332,  210,  164,  163,\n",
    "          66,  717,  592,   49])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_size 112\n",
      "map_size 2\n",
      "L 4\n",
      "mask_index length: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "img_size = 224\n",
    "p = patch_size = 112 # (7,14,28,56,112)\n",
    "map_size = img_size // patch_size\n",
    "L = map_size*map_size\n",
    "mask_index = torch.randperm(L)\n",
    "print('patch_size', patch_size)\n",
    "print('map_size', map_size)\n",
    "print('L', L)\n",
    "print('mask_index length:', (mask_index.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_index(N, keep_ratio):\n",
    "    \"\"\"\n",
    "    N: 16\n",
    "    norandom_num: 4\n",
    "    ori_index:    tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16])\n",
    "    index_shuffle:tensor([8, 11, 9, 4, 10, 2, 3, 0, 5, 6, 1, 7])\n",
    "    index_restore:tensor([12, 13, 14, 15, 16])\n",
    "    random_index: tensor([8, 11, 9, 4, 10, 2, 3, 0, 5, 6, 1, 7, 12, 13, 14, 15, 16])\n",
    "    \"\"\"\n",
    "    # create random_index from ori_index of a batch indexs\n",
    "    restore_num = int(N * keep_ratio)\n",
    "    ori_index = torch.range(0, N-1, dtype=int)\n",
    "    if N-1 < N-restore_num: # restore_num == 0\n",
    "        index_restore = torch.tensor([])\n",
    "    else:\n",
    "        index_restore = torch.range(N - restore_num, N-1, dtype=int) # 长度为 restore_num\n",
    "    index_shuffle = torch.randperm(N - restore_num) # 长度为 N - restore_num\n",
    "    random_index = torch.cat((index_shuffle, index_restore)).long()\n",
    "\n",
    "    assert len(ori_index) == len(random_index)\n",
    "    return ori_index, random_index\n",
    "\n",
    "def patchify(imgs):\n",
    "    \"\"\"\n",
    "    imgs: (N, 3, H, W)\n",
    "    mask: (N, 1, H, W)\n",
    "    x: (N, L, patch_size**2 *3)\n",
    "    \"\"\"\n",
    "    # p = 7 #cfg['model']['patch_size']\n",
    "    c = imgs.shape[1]\n",
    "    assert imgs.shape[2] == imgs.shape[3] and imgs.shape[2] % p == 0\n",
    "\n",
    "    h = w = imgs.shape[2] // p\n",
    "    x = imgs.reshape(shape=(imgs.shape[0], c, h, p, w, p))\n",
    "    x = torch.einsum('nchpwq->nhwpqc', x)\n",
    "    x = x.reshape(shape=(imgs.shape[0], h * w, p**2 * c))\n",
    "    return x\n",
    "    \n",
    "def unpatchify(x, p):\n",
    "    \"\"\"\n",
    "    x: (N, L, patch_size**2 *3)\n",
    "    imgs: (N, 3, H, W)\n",
    "    \"\"\"\n",
    "    h = w = int(x.shape[1]**.5)\n",
    "    assert h * w == x.shape[1]\n",
    "    c = x.shape[2] // (p*p)\n",
    "    x = x.reshape(shape=(x.shape[0], h, w, p, p, c))\n",
    "    x = torch.einsum('nhwpqc->nchpwq', x)\n",
    "    imgs = x.reshape(shape=(x.shape[0], c, h * p, h * p))\n",
    "    return imgs\n",
    "\n",
    "def fusion(imgs, ori_labels, patch_ratio, index_ratio):\n",
    "    N, C, H, W = imgs.shape\n",
    "    ori_index = torch.tensor([0, 1])\n",
    "    random_index = torch.tensor([1, 1])\n",
    "    pairs_imgs = imgs[torch.LongTensor(random_index), :, :]  # random imgs's place in a batch\n",
    "    pair_ori_labels = ori_labels[random_index]  # random labels's place in a batch\n",
    "    patchify_imgs = patchify(imgs)\n",
    "    pairs_patchify_imgs = patchify(pairs_imgs)\n",
    "    mask = torch.zeros(patchify_imgs.shape)\n",
    "    mask2 = torch.zeros(pairs_patchify_imgs.shape)\n",
    "    mask_label = torch.zeros(N, L, 1)\n",
    "    masks1 = torch.zeros(patchify_imgs.shape)\n",
    "    masks2 = torch.zeros(patchify_imgs.shape)\n",
    "\n",
    "    # 对batch中的每张img做fusion\n",
    "    for i in range(N):\n",
    "        one = torch.LongTensor(mask_index[:L // 2])  # 按照patches长度的50% 混合图1和图2的patches\n",
    "        two = torch.LongTensor(mask_index[L // 2:]) # one: tensor([1, 2]) 图1要保留的patches位置  two: tensor([4, 0]) 图2要保留的patches位置\n",
    "        mask_label[i].index_fill_(dim=0, index=one, value=ori_labels[i].squeeze())  # 把图1的ori_label的值赋给保留图一patches的位置\n",
    "        mask_label[i].index_fill_(dim=0, index=two, value=pair_ori_labels[i].squeeze())  # 把图2的ori_label的值赋给保留图二patches的位置\n",
    "        print('mask_label', mask_label.shape)\n",
    "        masks1[i].index_fill_(dim=0, index=one, value=ori_labels[i].squeeze())  \n",
    "        masks2[i].index_fill_(dim=0, index=two, value=pair_ori_labels[i].squeeze())  \n",
    "        mask[i].index_fill_(dim=0, index=one, value=1)\n",
    "        mask2[i].index_fill_(dim=0, index=two, value=1)\n",
    "        print('patchify_imgs', patchify_imgs.shape)\n",
    "        print('mask', mask.shape)\n",
    "        print('mask2', mask2.shape)\n",
    "\n",
    "    masked_patchify_img = torch.mul(mask, patchify_imgs)\n",
    "    pair_masked_patchify_img = torch.mul(mask2, pairs_patchify_imgs)\n",
    "    fusion_masked_img = torch.add(masked_patchify_img, pair_masked_patchify_img)\n",
    "    masks = torch.add(masks1, masks2)\n",
    "\n",
    "    # 反patch化 + 去patch化\n",
    "    fusion_masked_img = unpatchify(fusion_masked_img, p) # torch.Size([N, L, P*P])\n",
    "    masks = unpatchify(masks, p) # torch.Size([N, L, P*P])\n",
    "    mask_label = unpatchify(mask_label, 1) # torch.Size([N, L, P*P])  回到[N, 1, 224, 224]\n",
    "    return fusion_masked_img, masks, mask_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([2, 3, 224, 224])\n",
      "mask_label torch.Size([2, 4, 1])\n",
      "patchify_imgs torch.Size([2, 4, 37632])\n",
      "mask torch.Size([2, 4, 37632])\n",
      "mask2 torch.Size([2, 4, 37632])\n",
      "mask_label torch.Size([2, 4, 1])\n",
      "patchify_imgs torch.Size([2, 4, 37632])\n",
      "mask torch.Size([2, 4, 37632])\n",
      "mask2 torch.Size([2, 4, 37632])\n"
     ]
    }
   ],
   "source": [
    "label = torch.tensor([[1], [0]])\n",
    "# img = torch.ones(2,3,224,224)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor()])\n",
    "\n",
    "img_path = 'live.png'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "img = transform(img)\n",
    "img_path2 = 'spoof.png'\n",
    "img2 = Image.open(img_path2).convert('RGB')\n",
    "img2 = transform(img2)\n",
    "images = torch.stack((img, img2), dim=0)\n",
    "print(img.shape)\n",
    "print(img2.shape)\n",
    "print(images.shape)\n",
    "\n",
    "img, labels, label = fusion(imgs=images, ori_labels=label, patch_ratio=0.5, index_ratio=0.5)\n",
    "\n",
    "toPIL = transforms.ToPILImage() #这个函数可以将张量转为PIL图片，由小数转为0-255之间的像素值\n",
    "pic = toPIL(img[0])\n",
    "pic.save('img_test__{}_{}.png'.format(patch_size, 'img')) \n",
    "pic = toPIL(labels[0])\n",
    "pic.save('img_test__{}_{}.png'.format(patch_size, 'labels'))   \n",
    "pic = toPIL(label[0])\n",
    "pic.save('img_test_{}_{}.png'.format(patch_size, 'label')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = 'live.png'\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "a = np.array(image)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.expand_dims(float(1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(float(1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('m0.3.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "447ba208663b2121cd247c78f2487e737fc4f414dfe34a3b3fed215372bd8647"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
